#PARA +2 MUESTRAS RELACIONADAS usaremos la Q de Cochran
respuesta <- c(1,0,1,0,0,1,0,1,0,0,1,1,1,0,1,0,1,0,1,0,1,1,1,0,0,1,0,1,0,1,0)
Sujeto <- c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,7,7,7,8,8,8,9,9,9,10,10,10)
Canal <- factor(rep(c("iicial","anuncio","internet")))
datos <- data.frame(Sujeto,Canal,respuesta)
datos <- data.frame(Sujeto,Canal,respuesta)
#PARA +2 MUESTRAS RELACIONADAS usaremos la Q de Cochran
respuesta <- c(1,0,1,0,0,1,0,1,0,0,1,1,1,0,1,0,1,0,1,0,1,1,1,0,0,1,0,1,0,1)
datos
datos <- data.frame(Sujeto,Canal,respuesta)
datos
#PARA +2 MUESTRAS RELACIONADAS usaremos la Q de Cochran
respuesta <- c(1,0,1,0,0,1,0,1,0,0,1,1,1,0,1,0,1,0,1,0,1,1,1,0,0,1,0,1,0,1)
Sujeto <- c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,7,7,7,8,8,8,9,9,9,10,10,10)
Canal <- factor(rep(c("inicial","anuncio","internet")))
datos <- data.frame(Sujeto,Canal,respuesta)
datos
levels(datos$Canal) <- c("inicial","anuncio","internet")
ggbarstats(data=datos,x=respuesta,y=Canal,paired = TRUE,bf.message = FALSE)
#como este paquete aun no da los resultados los tenemos q sacar usando statrix
cochran_qtest(datos,respuesta ~Canal|Sujeto)
#como p es 0.90 no es estadisticamente significativo, si diese significativo tendriamos q mirar cuando, apra lo q usamos la de mcnemar
pairwise_mcnemar_test(datos,respuesta ~ Canal|Sujeto)
######### COMPARACIONES DE MEDIAS ###########################
#Comenzamos explorando los datos
hsb2 %>% get_summary_stats(write,type="mean_sd")
ggboxplot(y="write", data=hsb2,add=c("mean"),add.params=list(color='red'))
library(ggpubr)
ggboxplot(y="write", data=hsb2,add=c("mean"),add.params=list(color='red'))
#evaluemos los supuestos del modelo, ya q estamos con una prueba apramétrica
#outliers
hsb2 %>% identify_outliers(write)
#distribución normal
hsb2 %>%  shapiro_test(write)
ggqqplot(hsb2,x="write")
#vamos a hacer un t-test
t_test(write ~1,data=hsb2, mu=50)
cohens_d(write ~1,data=hsb2,mu=50)
#vamos a ahcer la de Yuen (no tiene en cuenta outliers)
hsb2 %>% filter(between(write,quantile(write,0.1),quantile(write,0.9))) %>% get_summary_stats(write,type="mean_sd")
######### COMPARACIONES DE MEDIAS ###########################
#Comenzamos explorando los datos
hsb2 %>% get_summary_stats(write,type="mean_sd")
hsb2 %>% filter(between(write,quantile(write,0.1),quantile(write,0.9))) %>% ggboxplot(y="write",add=c("mean"),add.params=list(color='red'))
#si los comprobamos los datos siguen sin ser normales, asi que no mola mucho usar esta prueba
library(DescTools)
YuenTTest(x=hsb2$write,mu=50)
#PRUEBA NO PARAMETRICA de WILCOXON para 1 MEUSTRA - comparamos la mediana
#ahora exploremos la mediana
hsb2 %>% get_summary_stats(write,type="median_iqr")
ggboxplot(y="write", data=hsb2,add=c("mean"),add.params=list(color='red'))
#veamos la asimetria de los datos con el histograma
gghistogram(hsb2, x="write", y="..density..",fill="steelblue",add_density = TRUE)
#ajustmos el modelo - rstatic
wilcox_test(write~1,data=hsb2,mu=50)
#esta pruab usa el orden y no los valores reales, por eso no es parametrica.
#calculamos el tamaño del efecto
wilcox_effsize(write ~1,data=hsb2,mu=50)
#representamos el resultado
gghistostats(x=write,data=hsb2,test.value = 50,type = "np",centrality.type = "median",test.value.size=TRUE,test.value.line=TRUE,bf.message=FALSE_)
#representamos el resultado
gghistostats(x=write,data=hsb2,test.value = 50,type = "np",centrality.parameter = "median",test.value.size=TRUE,test.value.line=TRUE,bf.message=FALSE_)
#representamos el resultado
gghistostats(x=write,data=hsb2,test.value = 50,type = "np",centrality.parameter = "nonparametric",test.value.size=TRUE,test.value.line=TRUE,bf.message=FALSE_)
#representamos el resultado
gghistostats(x=write,data=hsb2,test.value = 50,type = "nonparametric",centrality.parameter = "nonparametric",test.value.size=TRUE,test.value.line=TRUE,bf.message=FALSE_)
library(openintro)
head(hsb2)
#Con tidyverse
library(tidyverse)
## Tsudent para 2 mustras independientes
hsb2 %>% group_by(gender) %>% get_summary_stats(write, type="mean_sd")
library(ggpubr)
## Tsudent para 2 mustras independientes
hsb2 %>% group_by(gender) %>% get_summary_stats(write, type="mean_sd")
ggboxplot(x="gender", y="write",data=hsb2, add=c("mean"), add.params = list(color="red"))
ggboxplot(x="gender", y="write",data=hsb2, add=c("mean"), add.params = list(color="red"))
hsb2 %>% group_by(gender) %>% identify_outliers(write)
#si los comprobamos los datos siguen sin ser normales, asi que no mola mucho usar esta prueba
library(DescTools)
hsb2 %>% group_by(gender) %>% identify_outliers(write)
#ahora apra ve r las diferencias entre programas usaremos pruebas post-hoc
#Esto te compara las 3 proporciones, es decir als tres columnitas y solo ve diferncias entre la acadeimca y la vocacional
library(rstatix)
hsb2 %>% group_by(gender) %>% identify_outliers(write)
hsb2 %>% levene_test(write ~ gender) #rstatix
hsb2 %>% group_by(gender) %>% shapiro_test(write) #rstatix
ggqqplot(hsb2, x="write", facet.by = "gender")
t_test(write ~gender , data=hsb2)
t_test(write ~gender , data=hsb2, var.equal = False)# p<0.05
t_test(write ~gender , data=hsb2, var.equal = FALSE)# p<0.05
cohens_d(write ~ gender, data = hsb2)
### COMPARANDO PROPORCIONES
#1 MUESTRA
library(ggstatsplot)
theme(text=element_text(size=8), plot.subtitle = element_text(size=8)))
theme(text=element_text(size=8), plot.subtitle = element_text(size=8))
theme(text=element_text(size=8), plot.subtitle = element_text(size=8))
theme(text = element_text(size=8), plot.subtitle = element_text(size=8))
#+   theme(text = element_text(size=8), plot.subtitle = element_text(size=8))
ggbetweenstats(x=gender, y=write, data = hsb2, bf.message = FALSE)
get_summary_stats(write,type = "mean_sd")
library(openintro)
library(gmodels)
#Con tidyverse
library(tidyverse)
### COMPARANDO PROPORCIONES
#1 MUESTRA
library(ggstatsplot)
#ahora apra ve r las diferencias entre programas usaremos pruebas post-hoc
#Esto te compara las 3 proporciones, es decir als tres columnitas y solo ve diferncias entre la acadeimca y la vocacional
library(rstatix)
library(ggpubr)
#si los comprobamos los datos siguen sin ser normales, asi que no mola mucho usar esta prueba
library(DescTools)
#+   theme(text = element_text(size=8), plot.subtitle = element_text(size=8))
#+   #Cuando hay OUTLIERS usaremos la prueba ROBUSTA de YUEN : pruebas apramétricas de medias recortadas
##vemos la diferencia en la media rcortada. Aqui la prueba va a ser BILATERAL (decimos simplemente
#+#q es DIFERENTE, sin especificar direccion
#+#exploracion
hsb2 %>%  group_by(gender) %>% filter(between(write,
quantile(write,0.1),
quantile(write,0.9))) %>%
get_summary_stats(write,type = "mean_sd")
ggboxplot(x="gender", y="write", add=c("mean"), add.params = list(color='red'))
quantile(write, 0.9))) %>%   ggboxplot(x="gender", y="write", add=c("mean"), add.params = list(color='red'))
ggboxplot(x="gender", y="write", add=c("mean"), add.params = list(color='red'))
hsb2_recortado <- hsb2 %>%  group_by(gender) %>%  filter(between(write,
#diagrama box
hsb2_recortado <- hsb2 %>%  group_by(gender) %>%  filter(between(write,
quantile(write, 0.1),
quantile(write, 0.9)))
#PRUEBA NO PARAMETRICA de WILCOXON para 1 MEUSTRA - comparamos la mediana
#ahora exploremos la mediana
hsb2 %>% get_summary_stats(write,type="median_iqr")
## Tsudent para 2 mustras independientes
hsb2 %>% group_by(gender) %>% get_summary_stats(write, type="mean_sd") #get_summary_stats es de ggpub
ggboxplot(x="gender", y="write",data=hsb2, add=c("mean"), add.params = list(color="red"))
#evaluando los supuestos: una prueba paramétrica asume q no hay outliers, y normalidad
#identificamos los aoutliers así:
hsb2 %>% group_by(gender) %>% identify_outliers(write) #identify_outliers es de rstatix
#homogeneidad de varianza: levene test
hsb2 %>% levene_test(write ~ gender) #rstatix . El pvalues <0.05 la variabilidad no es homogenea en ambos grupos!
#tWelch vs Tstudent: cuando la varianza no es homogenea se usa mejor la t de welch
#chequo de normalidad de distribución
hsb2 %>% group_by(gender) %>% shapiro_test(write) #rstatix <0.05 ambas -> no normal
ggqqplot(hsb2, x="write", facet.by = "gender") # aqui se ve que no es mu normal
#¿Cómo ajustar un modelo de evaluar tstudent? rstatix
t_test(write ~gender , data=hsb2, var.equal = FALSE)# p<0.05 -> no iguales
# Calculando el tamaño de efecto: prueba d cohen
cohens_d(write ~ gender, data = hsb2)# tamaño 0.5 es moderado
#para comunicar los resultados hacemos un daigrama de cajas modificado
ggbetweenstats(x=gender, y=write, data = hsb2, bf.message = FALSE)
#diagrama box
hsb2_recortado <- hsb2 %>%  group_by(gender) %>%  filter(between(write,
quantile(write, 0.1),
quantile(write, 0.9)))
ggboxplot(data=hsb2_recortado,x="gender", y="write", add=c("mean"), add.params = list(color="red"))
ggboxplot(x="gender", y="write",data=hsb2, add=c("mean"), add.params = list(color="red"))
hsb2_recortado %>% levene_test(write ~ gender)
quantile(write,0.9))) %>% levene_test(write ~ gender)
#evaluamos de nuevo los supuestos del modelo.
#prueba de levene
hsb2 %>%  filter(between(write,quantile(write,0.1),quantile(write,0.9))) %>% levene_test(write ~ gender)
#evaluamos de nuevo los supuestos del modelo.
#prueba de levene
hsb2_filtrado <- hsb2 %>%  filter(between(write,quantile(write,0.1),quantile(write,0.9)))
View(hsb2_filtrado)
View(hsb2_filtrado)
hsb2_filtrado  %>% levene_test(write ~ gender)
hsb2 %>% shapiro_test(write)
hsb2_recortado %>% shapiro_test(write) #para el shapiro tnemos q meterla antes
View(hsb2_recortado)
View(hsb2_filtrado)
hsb2_filtrado %>% ggqqplot(x= "write", facet.by = "gender")
YuenTTest(write ~ gender, data=hsb2) #esta te recorta por defecto el 20%
#Tamaño del efecto de la prueba de yuen
library(WRS2)
yuen.effect.ci(writ ~gender, data=hsb2,boot=10)
yuen.effect.ci(write ~gender, data=hsb2,boot=10)
ggbetweenstats(x=gender,y=write, data=hsb2, tr=0.2, type="robust", bf.message = FALSE)
yuen.effect.ci(write ~gender, data=hsb2,boot=10) # resulta 0.35: efewcto moderado
#comunicación de resultado
ggbetweenstats(x=gender,y=write, data=hsb2, tr=0.2, type="robust", bf.message = FALSE)
hsb2 %>%  group_by(gender)
hsb2 %>%  group_by(gender) %>% get_summary_stats(write, type="median")
ggqqplot(x="gender", y="write", adta=hsb2, add = c("median"), add.params = list(color="red"))
ggqqplot(x="gender", y="write", data=hsb2, add = c("median"), add.params = list(color="red"))
ggboxplot(x="gender", y="write", data=hsb2, add = c("median"), add.params = list(color="red"))
gghistogram(hsb2, x="write",add="median", rug = TRUE, bins=15, color="gender", fill="gender", palette="Kark2")
wilcox_test(writ ~gender,data=hsb2)
wilcox_test(write ~gender,data=hsb2)
wilcox_effsize(write ~ gender, data=hsb2)
ggbetweenstats(x=gender, y=write, data=hsb2, type="np", bf.message = FALSE)
hsb2 %>% dplyr::select(write,read) %>% get_summary_stats(type="mean_sd")
ggboxplot(x="test", y="score", data=hsb2.long, add=c("mean"), add.params = list(color="red"))
hsb2_long <- hsb2 %>%  pivot_longer(c(write,read), names_to="test", values_to = "score") %>% arrange(test,id)
ggboxplot(x="test", y="score", data=hsb2.long, add=c("mean"), add.params = list(color="red"))
ggboxplot(x="test", y="score", data=hsb2_long, add=c("mean"), add.params = list(color="red"))
hsb2
hsb2_long
hsb2 <- hsb2 %>% mutate(differences=read-write)
hsb2 %>% identify_outliers(differences)
hsb2 %>% shapiro_test(differences)
ggqqplot(hsb2,"differences")
hsb2_long %>% levene_test(score ~ test)
t_test(score ~test, data=hsb2_long, paired = TRUE )
cohens_d(score ~ test, data=hsb2_long, paired = TRUE)
ggwithinstats(x=test,y=score, data=hsb2_long, bf.message = FALSE)
quantile(.,.9)))) %>% get_summary_stats(type="median")
quantile(.,.9)))) %>% get_summary_stats(type="mean_sd")
quantile(.,.9))))# %>% get_summary_stats(type="mean_sd")
hsb2 %>%  dplyr::select(write, read) %>% filter_all(all_vars(between(.,quantile(.,.1),quantile(.,.9))))# %>% get_summary_stats(type="mean_sd")
hsb2 %>%  dplyr::select(write, read) %>% filter_all(all_vars(between(.,quantile(.,.1),quantile(.,.9)))) %>% get_summary_stats(type="mean_sd")
quantile(.,.9)))) %>% get_summary_stats()
hsb2 %>%  dplyr::select(write, read) %>% filter_all(all_vars(between(.,quantile(.,.1),
quantile(.,.9)))) %>% get_summary_stats()
hsb2 %>% filter(between(score,
quantile(score, 0.1),
quantile(score, 0.9)))
hsb2_long %>% filter(between(score,
quantile(score, 0.1),
quantile(score, 0.9)))
hsb2_long %>% filter(between(score,
quantile(score, 0.1),
quantile(score, 0.9)))
hsb2_long %>% filter(between(score,
quantile(score, 0.1),
quantile(score, 0.9)))
hsb2_long %>% filter(between(score,
quantile(score, 0.1),
quantile(score, 0.9))) %>% ggboxplot(x="test", y="score", add=c("mean"), add.params = list(color="red"))
quantile(differences,0.9))) %>% shapiro_test(differences)
#test shapiro
hsb2 %>% filter(between(differences,
quantile(differences,0.1),
quantile(differences,0.9))) %>% shapiro_test(differences)
quantile(differences,0.9))) %>% ggqqplot(x="differences")
#qqplot
hsb2 %>% filter(between(differences,
quantile(differences,0.1),
quantile(differences,0.9))) %>% ggqqplot(x="differences")
#qqplot
hsb2 %>% filter(between(differences,
quantile(differences,0.1),
quantile(differences,0.9))) %>% ggqqplot(x="differences") #no se cumple noramlidad (auqnue sea robusta la normalidad se pide
#test de yuen
YuenTTest(x=hsb2$read,y=hsb2$read, paired=TRUE)#YuenTTest(write ~ gender, data=hsb2)
hsb2$read
#test de yuen
YuenTTest(x=hsb2$read,y=hsb2$write, paired=TRUE)#YuenTTest(write ~ gender, data=hsb2)
dep.effect(x=hsb2$read,y=hsb2$write,tr=0.2,nboot=10)
#de aqui nos quedamos con el Est de AKP (-0.06), osea lo q sería un efecto de mierda, no?
#comunica resultados
ggwithinstats(x=test, y=score, data=hsb2_long, tr=0.2, type="r", bf.message = FALSE)
#comunicación de resultado
ggbetweenstats(x=gender,y=write, data=hsb2, tr=0.2, type="robust", bf.message = FALSE)
#comunicación de resultado
ggbetweenstats(x=gender,y=write, data=hsb2, tr=0.2, type="r", bf.message = FALSE)
#de aqui nos quedamos con el Est de AKP (-0.06), osea lo q sería un efecto de mierda, no?
#comunica resultados
ggwithinstats(x=test, y=score, data=hsb2_long, tr=0.2, type="r", bf.message = FALSE)
### PRUEBA ROBUSTA YUEN
#ara tenemos q filtrar el 20% de extremos
hsb2 %>%  dplyr::select(write, read) %>% filter_all(all_vars(between(.,quantile(.,.1),quantile(.,.9)))) %>% get_summary_stats()
###### 2 MUESTRAS RELACIONADAS NO PARAMETRICAS
hsb2 %>%  dplyr::select(write,read) %>% get_summary_stats(type = "median_iqr")
#### PRUEBAS NO PARAMETRICAS #########
#cuando los datos no siguen distribución normal usamos pruebas no parametricas y tnemos 2 grupos
#se llama prueba U de MannWhitney
#xplorando los datos: calculamos la MEDIANA
hsb2 %>%  group_by(gender) %>% get_summary_stats(write, type="median")
ggboxplot(x="test", y="score", data=hsb2_long, add=c("median"), add.params = list(color="red"))
#supuestos: no outliers, distribucion simetrica
hsb2 %>% gghistogram(x="differences", y="..density..", fill="steelblue", add_density = TRUE)
#test wilcox
wilcox_test(score ~ test, data=hsb2_long, paired = TRUE)
#test de yuen
YuenTTest(x=hsb2$read,y=hsb2$write, paired=TRUE)#YuenTTest(write ~ gender, data=hsb2) # p 0.009 -> diferentes
YuenTTest(score ~ test, data=hsb2_long, paired = TRUE)
#test wilcox
wilcox_test(score ~ test, data=hsb2_long, paired = TRUE)
#tamaño efecto
wilcox_effsize(score ~test, data=hsb2_long, paired = TRUE)
#resultados
ggwithinstats(x=test,y=score, data=hsb2_long, ggstastplot.layer=FALSE, messages=FALSE, typ="np", bf.message = FALSE)
gc()
#######ejercicios obligatorios del T3
# 1 Impuestos
datos <- data.frame(name=c("impuestos","servicios"), count=c(624, 1200-624))
rm=list()
rm(list = ls())
#######ejercicios obligatorios del T3
# 1 Impuestos
datos <- data.frame(name=c("impuestos","servicios"), count=c(624, 1200-624))
datos
ggpiestats(datos, x=name, counts=count, bf.message=FALSE)
library(ggstatsplot)
ggpiestats(datos, x=name, counts=count, bf.message=FALSE)
#2 genetica y crimen
Convictions <-matrix(c(2, 10, 15, 3),
nrow = 2,
dimnames = list(c("Dizygotic", "Monozygotic"),
c("Convicted", "Not convicted")))
#La prueba de independencia Chi-cuadrado y la prueba de Fisher se utilizan para probar la relación
#entre dos variables categóricas. O dicho de otro modo, examina si las filas y columnas de una tabla
#de contingencia están asociadas de manera estadísticamente significativa.
as.data.frame(as.table(Convictions))
ggbarstats
#Otro ejemplo
M <- as.table(rbind(c(762, 327, 468), c(484,239,477)))
dimnames(M) <- list(gender=c("M","F"),
party=c("Democrat","Independent", "Republican"))
M
M
Convictions
Convictions
typeof(M)
typeof(M)
dimnames(C) <- list(twin=c("Dizygotic", "Monozygotic"),
Crime=c("Convicted", "Not convicted"))
C
C <- as.table(rbind(c(2,15),c(10,3)))
C
dimnames(C) <- list(twin=c("Dizygotic", "Monozygotic"),
Crime=c("Convicted", "Not convicted"))
C
ggbarstats( data = as.data.frame(as.table(Convictions)),
x = Var1,
y = Var2,
counts = Freq)
ggbarstats(data = as.data.frame(M),
x= gender, y = party, counts = Freq,
bf.message = FALSE)
ggbarstats( data = as.data.frame(C),
x = Crime, y = twin, counts = Freq)
ggbarstats( data = as.data.frame(C),
x = twin, y = Crime, counts = Freq)
ggbarstats( data = as.data.frame(as.table(Convictions)),
x = Var1,
y = Var2,
counts = Freq)
ggbarstats( data = as.data.frame(C),
x = twin, y = Crime, counts = Freq)
#cuando tenemos pocos datos hay q hacer la prueba de Fisher, pero esa no está en ggstats
fisher_test(Convictions, alternative = "less")
library(rstatix)
#cuando tenemos pocos datos hay q hacer la prueba de Fisher, pero esa no está en ggstats
fisher_test(Convictions, alternative = "less")
#
#3. Abortos inducidos
data(infert, package = "datasets")
head(infert)
table(infert$education, infert$induced)
infert
#tenemos dos variables cualitativas: educacion y abortos,m cada una con tres niveles.para esto se usa ggbar
ggbarstats(data=infert,x=induced,y=education)
I <- table(infert$education, infert$induced)
I
#¿Cómo saber si ahy correlacion entre ambas variables con 3 categorias?
#Como queremos comparar las proporciones para más de 2 muestras, utilizamos la prueba de independencia de Chi-cuadrado
#existe erlacion significativa entre educacion y numero de abortos inducidos, aunque el efecto es pequeño (0.16)
#Para ver diferencias entre categorias ebemos hacer comparaciones multiples pareadas
pairwise_prop_test(I)
M
#¿Cómo saber si ahy correlacion entre ambas variables con 3 categorias?
#Como queremos comparar las proporciones para más de 2 muestras, utilizamos la prueba de independencia de Chi-cuadrado
#existe erlacion significativa entre educacion y numero de abortos inducidos, aunque el efecto es pequeño (0.16)
#Para ver diferencias entre categorias ebemos hacer comparaciones multiples pareadas
pairwise_prop_test(M)
#4. Artitris
data(Arthritis)
library
#4. Artitris
library(vcd)
data(Arthritis)
head(Arthritis)
table(Arthritis[which(Arthritis$Treatment=="Treated"),5])
datos <- Arthritis %>%
filter(Treatment == "Treated" & Improved != "Some") %>%
mutate(Improved = droplevels(Improved)) #borra la categoría fantasma
datos
head(datos)
summary(datos)
datos
datos %>% group_by(Improved) %>% get_summary_stats(Age, type="mean_sd")
#outliers
datos %>% group_by(Improved) %>% identify_outliers(Age)
#levene
#levene test
datos %>%  levene_test(Age ~ Improved)
#shapiro
datos %>% group_by(Improved) %>% shapiro_test(Age)
ggqqplot(datos, x="Age", facet.by = "Improved") # aqui se ve que no es mu normal
library(ggpubr)
ggqqplot(datos, x="Age", facet.by = "Improved") # aqui se ve que no es mu normal
#yo diria q lo mejor es una de Yuen, q es aprametrica pero sin outliers
#esa se ahce asi:
YuenTTest(Age ~ Improved, data=datos) #esta te recorta por defecto el 20% #DescTools# resultado significativo
library(WSR2)
library(WRS2)
library(DescTools)
#yo diria q lo mejor es una de Yuen, q es aprametrica pero sin outliers
#esa se ahce asi:
YuenTTest(Age ~ Improved, data=datos) #esta te recorta por defecto el 20% #DescTools# resultado significativo
#Tamaño del efecto de la prueba de yuen
library(WRS2)
yuen.effect.ci(Age ~Improved, data=hsb2,boot=10) # resulta 0.35: efewcto moderado
yuen.effect.ci(Age ~Improved, data=datos,boot=10) # resulta 0.35: efewcto moderado
#comunicación de resultado
ggbetweenstats(x=Improved,y=Age, data=datos, tr=0.2, type="r", bf.message = FALSE)
#encontramos 2 outliers, creo q tendremos q suar el robusto de yuen
#levene
#levene test
datos %>%  levene_test(Age ~ Improved) #es < 0.05 asi q es ligeramente significativa la diferencias de variabilidad
#5. Cebada
library(MASS)
head(immer)
#tenemos ahora 2 muestras relacionadas, un mismo sitio con dos medidas cada uno. Hagamos test parametrico, robusto, y no parametrico
#primero cambiar a formato alrgo
immer_largo <- immer %>%   pivot_longer(Y1:Y2, names_to = "variable", values_to = "valor") %>% mutate(variable = as.factor(variable))
library(tidyverse)
#tenemos ahora 2 muestras relacionadas, un mismo sitio con dos medidas cada uno. Hagamos test parametrico, robusto, y no parametrico
#primero cambiar a formato alrgo
immer_largo <- immer %>%   pivot_longer(Y1:Y2, names_to = "variable", values_to = "valor") %>% mutate(variable = as.factor(variable))
immer_largo
summary(immer_largo)
#las tres pruebas posibles apra dos muestras relacionadas son:
# outliers
immer <- immer %>% mutate(differences=Y2-Y1)
hsb2 %>% identify_outliers(differences)
immer %>% identify_outliers(differences)
#levene
immer %>% shapiro_test(differences) #no son diferentes a la normalidad
ggqqplot(immer,"differences")
#levene: supuestamente no es necesario al darse por sentado q al ser del mismo sujeto son similares
immer_long %>% levene_test(valor ~ variable)
#levene: supuestamente no es necesario al darse por sentado q al ser del mismo sujeto son similares
immer_largo %>% levene_test(valor ~ variable)
#shaphiro
immer %>% shapiro_test(differences) #no son diferentes a la normalidad
#no hemos chequeao si siguen siendo diferentes cuando recortamos los datos
datos %>% filter(between(write,quantile(write,0.1),quantile(write,0.9))) %>% levene_test(Age ~ Improved)
#no hemos chequeao si siguen siendo diferentes cuando recortamos los datos
datos %>% filter(between(Age,quantile(write,0.1),quantile(write,0.9))) %>% levene_test(Age ~ Improved)
#encontramos 2 outliers, creo q tendremos q suar el robusto de yuen
#levene
#levene test
datos %>%  levene_test(Age ~ Improved) #es < 0.05 asi q es ligeramente significativa la diferencias de variabilidad
#no hemos chequeao si siguen siendo diferentes cuando recortamos los datos
datos %>% filter(between(write,quantile(write,0.1),quantile(write,0.9))) %>% levene_test(Age ~ Improved)
#no hemos chequeao si siguen siendo diferentes cuando recortamos los datos
datos %>% filter(between(write,quantile(Age,0.1),quantile(write,0.9))) %>% levene_test(Age ~ Improved)
#no hemos chequeao si siguen siendo diferentes cuando recortamos los datos
datos %>% filter(between(Age,quantile(Age,0.1),quantile(Age,0.9))) %>% levene_test(Age ~ Improved)
datos
#encontramos 2 outliers, creo q tendremos q suar el robusto de yuen
#levene
#levene test
datos %>%  levene_test(Age ~ Improved) #es < 0.05 asi q es ligeramente significativa la diferencias de variabilidad
#no hemos chequeao si siguen siendo diferentes cuando recortamos los datos
datos %>% filter(between(Age,quantile(Age,0.1),quantile(Age,0.9))) %>% levene_test(Age ~ Improved)
datos %>% group_by(Improved) %>%  filter(between(Age,
quantile(Age, 0.1),
quantile(Age, 0.9)))  %>% shapiro_test(Age)
#comunicación de resultado
ggbetweenstats(x=Improved,y=Age, data=datos, tr=0.2, type="r", bf.message = TRUE)
#puesto que no hay outliers, y cumple los supuestos de normalidad (shapiro P=0.079) optaremos por una prueba aprametrica ttest
ggwithinstats(data = immer_largo,
x = variable,
y = valor,
type = "p")  #INDICA
data(hsb2)
library(openintro)
data(hsb2)
hsb2 %>%  group_by(prog) %>% get_summary_stats(write, type ="mean_sd")
ggboxplot(hsb2, x="prog", y="write"), orientation="horizontal")
ggboxplot(hsb2, x="prog", y="write", orientation="horizontal")
#outliers
hsb2 %>%  group_by(prog) %>% identify_outliers(write)
#normalidad
fit <- lm(write ~ prog, data=hsb2)
ggqqplot(residuals(fit))
shapiro_test(residuals(fit))
shapiro_test(residuals(fit)) # signioficativamente diferente
#lo aplicamos a los residuos del anova o moelo lineal
#homogeneidad de varianza
plot(fit,1)
hsb2 %>% levene_test(write ~prog)
#anova test
hsb2 %>% anova_test(writ ~prog)
#anova test
hsb2 %>% anova_test(write ~prog)
#¿Como saber cual es el grupo diferente? Post hoc multiple comparison
hsb2 %>% pairwise_t_test(write ~ prog, p.adjust.method = "bonferroni", pool.sd = TRUE)
#presentar
ggbetweenstats(x=prog,y=ewrite,data=hsb2, p.adjust.method = "bonferroni",bf.message = FALSE, var.equal = TRUE)
#presentar
ggbetweenstats(x=prog,y=write,data=hsb2, p.adjust.method = "bonferroni",bf.message = FALSE, var.equal = TRUE)
#SI NO HAY HOMOGENEIDAD DE VARIANZA: Si esto no se da es un supuesto GRAVE. hay q usar otra prueba
#hay q usar la de welch
hsb2 %>%  welch_anova_test(writ ~ prog)
#SI NO HAY HOMOGENEIDAD DE VARIANZA: Si esto no se da es un supuesto GRAVE. hay q usar otra prueba
#hay q usar la de welch
hsb2 %>%  welch_anova_test(write ~ prog)
#para el post-hoc el cambio lo ahcemos en el pool.sd
hsb2 %>% pairwise_t_test(write ~ prog, p.adjust.method = "bonferroni", pool.sd = FALSE)#hemos peusto varianzas iguales=TRUE
#ahora ahy una que no da significativo!!
#represetar
ggbetweenstats(x=prog,y=write, data=hsb2, p.adjust.method="none",bf.message = FALSE,var.equal = FALSE)
#normalidad
fit <- lm(write ~ prog, data=hsb2)
